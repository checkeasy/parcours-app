/**
 * Service de scraping Airbnb avec streaming SSE
 *
 * Ce service g√®re l'int√©gration compl√®te avec le service de scraping externe :
 * 1. Lance l'extraction
 * 2. √âcoute le stream SSE
 * 3. T√©l√©charge et convertit les images en base64
 * 4. Transforme les donn√©es en format parcours
 * 5. Envoie le webhook √† Bubble.io
 */

import fetch from 'node-fetch';
import { EventSource } from 'eventsource';
import { SCRAPING_CONFIG } from '../config/scrapingConfig';
import { sendWebhookToBubble } from './webhookService';
import type {
  ExtractionStartResponse,
  CollectedStreamData,
  ScrapingResult,
  SSEEvent,
  AIGeneratedTask,
  ScrapeAndCreateParcoursPayload
} from '../types/scraping';

/**
 * Lance une extraction Airbnb
 */
async function startExtraction(airbnbUrl: string): Promise<string> {
  const url = `${SCRAPING_CONFIG.scrapingServiceUrl}${SCRAPING_CONFIG.endpoints.extract}`;
  
  console.log(`üåê Lancement extraction Airbnb...`);
  console.log(`   URL: ${airbnbUrl}`);
  console.log(`   Endpoint: ${url}`);
  
  const response = await fetch(url, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ url: airbnbUrl })
  });
  
  if (!response.ok) {
    throw new Error(`Erreur HTTP ${response.status}: ${response.statusText}`);
  }
  
  const data = await response.json() as ExtractionStartResponse;
  
  console.log(`‚úÖ Extraction lanc√©e: ${data.extraction_id}`);
  
  return data.extraction_id;
}

/**
 * √âcoute le stream SSE et collecte les donn√©es
 */
async function listenToStream(extractionId: string): Promise<CollectedStreamData> {
  return new Promise((resolve, reject) => {
    const streamUrl = `${SCRAPING_CONFIG.scrapingServiceUrl}${SCRAPING_CONFIG.endpoints.stream}/${extractionId}?user_type=${SCRAPING_CONFIG.streaming.defaultUserType}&delay_ms=${SCRAPING_CONFIG.streaming.delayMs}`;
    
    console.log(`üì° Connexion au stream SSE...`);
    console.log(`   URL: ${streamUrl}`);
    
    const eventSource = new EventSource(streamUrl);
    
    const collectedData: CollectedStreamData = {
      metadata: null,
      propertyInfo: null,
      stats: null,
      rooms: {},
      tasks: {}
    };
    
    let eventCount = 0;
    
    // Timeout de s√©curit√©
    const timeout = setTimeout(() => {
      eventSource.close();
      reject(new Error(`Timeout: extraction trop longue (>${SCRAPING_CONFIG.streaming.extractionTimeout}ms)`));
    }, SCRAPING_CONFIG.streaming.extractionTimeout);
    
    eventSource.onmessage = (event: any) => {
      try {
        const message = JSON.parse(event.data) as SSEEvent;
        eventCount++;
        
        console.log(`   üì® √âv√©nement ${eventCount}: ${message.type}`);
        
        switch (message.type) {
          case 'metadata':
            collectedData.metadata = message.data;
            break;
            
          case 'property_info':
            collectedData.propertyInfo = message.data;
            console.log(`      Propri√©t√©: ${message.data.name}`);
            break;
            
          case 'stats':
            collectedData.stats = message.data;
            console.log(`      Stats: ${message.data.rooms_found} pi√®ces, ${message.data.total_images} images`);
            break;
            
          case 'room':
            collectedData.rooms[message.room_type] = message.data;
            console.log(`      Pi√®ce: ${message.room_type} (${message.data.images_count} images)`);
            break;
            
          case 'tasks':
            collectedData.tasks[message.room_type] = message.data;
            console.log(`      T√¢ches: ${message.room_type} (${message.data.total_tasks} t√¢ches)`);
            break;
            
          case 'complete':
            clearTimeout(timeout);
            eventSource.close();
            console.log(`‚úÖ Stream termin√©: ${eventCount} √©v√©nements re√ßus`);
            resolve(collectedData);
            break;
            
          case 'error':
            clearTimeout(timeout);
            eventSource.close();
            reject(new Error(message.error));
            break;
        }
      } catch (err) {
        console.error('‚ùå Erreur parsing SSE:', err);
      }
    };
    
    eventSource.onerror = (error: any) => {
      clearTimeout(timeout);
      eventSource.close();
      console.error('‚ùå Erreur connexion SSE:', error);
      reject(new Error('Erreur de connexion au stream'));
    };
  });
}

/**
 * D√©termine le type de parcours bas√© sur les donn√©es scrap√©es
 * Par d√©faut: 'menage' (peut √™tre √©tendu avec de la logique plus complexe)
 */
function determineParcoursType(data: CollectedStreamData): 'menage' | 'voyageur' {
  // Pour l'instant, on retourne toujours 'menage'
  // Cette fonction peut √™tre √©tendue pour analyser les donn√©es et d√©terminer le type
  // Par exemple: si beaucoup de t√¢ches li√©es au check-in/check-out ‚Üí 'voyageur'
  
  return 'menage';
}

/**
 * Extrait l'emoji d'un titre de t√¢che
 */
function extractEmoji(title: string): string {
  const emojiMatch = title.match(/^([\u{1F300}-\u{1F9FF}])/u);
  return emojiMatch ? emojiMatch[1] : '‚úì';
}

/**
 * Nettoie le titre en retirant l'emoji
 */
function cleanTitle(title: string): string {
  return title.replace(/^[\u{1F300}-\u{1F9FF}\s]+/u, '').trim();
}

/**
 * Transforme les donn√©es scrap√©es en format parcours CheckEasy
 */
function transformToParcoursFormat(
  data: CollectedStreamData,
  parcoursType: 'menage' | 'voyageur'
): Omit<ScrapingResult, 'extractionId' | 'parcoursType'> {
  
  console.log(`üîÑ Transformation des donn√©es en format parcours...`);
  
  const pieces = Object.entries(data.rooms).map(([roomType, roomData]) => {
    const tasksData = data.tasks[roomType];
    
    // Mapper le nom de la pi√®ce
    const mappedRoomName = SCRAPING_CONFIG.roomTypeMapping[roomType as keyof typeof SCRAPING_CONFIG.roomTypeMapping] || roomType;
    
    // Transformer les t√¢ches AI
    const tasks = tasksData?.ai_generated_tasks.map((task: AIGeneratedTask) => ({
      emoji: extractEmoji(task.title),
      titre: cleanTitle(task.title),
      description: task.description,
      photoObligatoire: task.photo_required
    })) || [];
    
    // Transformer les photos
    const photos = roomData.images.map(img => ({
      url: img.url,
      filename: img.filename,
      alt_text: img.alt_text
    }));
    
    console.log(`   ‚úì ${mappedRoomName}: ${tasks.length} t√¢ches, ${photos.length} photos`);
    
    return {
      nom: mappedRoomName,
      quantite: 1,
      tasks,
      photos
    };
  });
  
  const totalTasks = pieces.reduce((sum, piece) => sum + piece.tasks.length, 0);
  const totalImages = pieces.reduce((sum, piece) => sum + piece.photos.length, 0);
  
  console.log(`‚úÖ Transformation termin√©e: ${pieces.length} pi√®ces, ${totalTasks} t√¢ches, ${totalImages} images`);
  
  return {
    propertyInfo: {
      name: data.propertyInfo?.name || 'Propri√©t√© Airbnb',
      title: data.propertyInfo?.title || 'Propri√©t√© Airbnb',
      totalImages: data.stats?.total_images || 0
    },
    pieces,
    stats: {
      totalRooms: pieces.length,
      totalTasks,
      totalImages
    }
  };
}

/**
 * Fonction principale : Scrape et cr√©e le parcours
 */
export async function scrapeAndCreateParcours(
  payload: ScrapeAndCreateParcoursPayload
): Promise<ScrapingResult> {
  
  const { url, conciergerieID, userID, isTestMode, parcoursType: requestedParcoursType } = payload;
  
  console.log(`\n${'='.repeat(60)}`);
  console.log(`üöÄ SCRAPING ET CR√âATION DE PARCOURS`);
  console.log(`${'='.repeat(60)}`);
  console.log(`   URL Airbnb: ${url}`);
  console.log(`   Conciergerie: ${conciergerieID}`);
  console.log(`   User: ${userID}`);
  console.log(`   Mode test: ${isTestMode ? 'OUI' : 'NON'}`);
  console.log(`${'='.repeat(60)}\n`);
  
  try {
    // 1. Lancer l'extraction
    const extractionId = await startExtraction(url);
    
    // 2. √âcouter le stream et collecter les donn√©es
    const scrapedData = await listenToStream(extractionId);
    
    // 3. D√©terminer le type de parcours (√âTAPE 2 OBLIGATOIRE)
    const parcoursType = requestedParcoursType || determineParcoursType(scrapedData);
    console.log(`\nüìã Type de parcours d√©termin√©: ${parcoursType.toUpperCase()}`);
    
    // 4. Transformer en format parcours
    const parcoursData = transformToParcoursFormat(scrapedData, parcoursType);
    
    // 5. Pr√©parer les donn√©es pour le webhook
    const logementData = {
      nom: parcoursData.propertyInfo.name,
      logementId: extractionId,
      modele: parcoursType,
      pieces: parcoursData.pieces,
      piecesPhotos: parcoursData.pieces.reduce((acc, piece) => {
        acc[piece.nom] = piece.photos;
        return acc;
      }, {} as Record<string, any[]>)
    };
    
    // 6. Envoyer webhook √† Bubble.io
    console.log(`\nüì§ Envoi du webhook √† Bubble.io...`);
    await sendWebhookToBubble({
      conciergerieID,
      userID,
      isTestMode,
      logementData
    });
    
    console.log(`\n${'='.repeat(60)}`);
    console.log(`‚úÖ PARCOURS CR√â√â AVEC SUCC√àS`);
    console.log(`${'='.repeat(60)}\n`);
    
    return {
      extractionId,
      parcoursType,
      ...parcoursData
    };
    
  } catch (error) {
    console.error(`\n${'='.repeat(60)}`);
    console.error(`‚ùå ERREUR LORS DU SCRAPING`);
    console.error(`${'='.repeat(60)}`);
    console.error(error);
    console.error(`${'='.repeat(60)}\n`);
    throw error;
  }
}


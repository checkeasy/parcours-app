/**
 * Service de scraping Airbnb avec streaming SSE
 *
 * Ce service g√®re l'int√©gration compl√®te avec le service de scraping externe :
 * 1. Lance l'extraction
 * 2. √âcoute le stream SSE
 * 3. T√©l√©charge et convertit les images en base64
 * 4. Transforme les donn√©es en format parcours
 * 5. Envoie le webhook √† Bubble.io
 */

import fetch from 'node-fetch';
import { EventSource } from 'eventsource';
import { SCRAPING_CONFIG } from '../config/scrapingConfig';
import { sendWebhookToBubble } from './webhookService';
import type {
  ExtractionStartResponse,
  CollectedStreamData,
  ScrapingResult,
  SSEEvent,
  AIGeneratedTask,
  ScrapeAndCreateParcoursPayload
} from '../types/scraping';

/**
 * T√©l√©charge une image depuis une URL et la convertit en base64
 */
async function downloadAndConvertToBase64(imageUrl: string, index: number): Promise<string> {
  try {
    console.log(`      üì• [${index + 1}] T√©l√©chargement: ${imageUrl.substring(0, 80)}...`);

    const response = await fetch(imageUrl);

    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }

    // R√©cup√©rer le buffer de l'image
    const buffer = await response.buffer();

    // D√©terminer le type MIME depuis les headers ou l'URL
    const contentType = response.headers.get('content-type') || 'image/jpeg';

    // Convertir en base64
    const base64 = buffer.toString('base64');
    const dataUrl = `data:${contentType};base64,${base64}`;

    const sizeKB = (buffer.length / 1024).toFixed(2);
    const preview = dataUrl.substring(0, 50);
    console.log(`      ‚úÖ [${index + 1}] Converti: ${sizeKB} KB - Preview: ${preview}...`);

    return dataUrl;
  } catch (error: any) {
    console.error(`      ‚ùå [${index + 1}] Erreur t√©l√©chargement image: ${error.message}`);
    console.error(`      ‚ö†Ô∏è  [${index + 1}] Retour de l'URL originale: ${imageUrl}`);
    // Retourner l'URL originale en cas d'erreur
    return imageUrl;
  }
}

/**
 * T√©l√©charge et convertit toutes les images d'une pi√®ce en base64
 */
async function downloadRoomImages(roomImages: any[]): Promise<string[]> {
  console.log(`   üì∏ T√©l√©chargement de ${roomImages.length} images...`);

  const base64Images: string[] = [];

  for (let i = 0; i < roomImages.length; i++) {
    const image = roomImages[i];
    const base64Image = await downloadAndConvertToBase64(image.url);
    base64Images.push(base64Image);
  }

  console.log(`   ‚úÖ ${base64Images.length} images converties en base64`);

  return base64Images;
}

/**
 * Lance une extraction Airbnb
 */
async function startExtraction(airbnbUrl: string): Promise<string> {
  const url = `${SCRAPING_CONFIG.scrapingServiceUrl}${SCRAPING_CONFIG.endpoints.extract}`;
  
  console.log(`üåê Lancement extraction Airbnb...`);
  console.log(`   URL: ${airbnbUrl}`);
  console.log(`   Endpoint: ${url}`);
  
  const response = await fetch(url, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ url: airbnbUrl })
  });
  
  if (!response.ok) {
    throw new Error(`Erreur HTTP ${response.status}: ${response.statusText}`);
  }
  
  const data = await response.json() as ExtractionStartResponse;
  
  console.log(`‚úÖ Extraction lanc√©e: ${data.extraction_id}`);
  
  return data.extraction_id;
}

/**
 * √âcoute le stream SSE et collecte les donn√©es
 */
async function listenToStream(extractionId: string): Promise<CollectedStreamData> {
  return new Promise((resolve, reject) => {
    const streamUrl = `${SCRAPING_CONFIG.scrapingServiceUrl}${SCRAPING_CONFIG.endpoints.stream}/${extractionId}?user_type=${SCRAPING_CONFIG.streaming.defaultUserType}&delay_ms=${SCRAPING_CONFIG.streaming.delayMs}`;
    
    console.log(`üì° Connexion au stream SSE...`);
    console.log(`   URL: ${streamUrl}`);
    
    const eventSource = new EventSource(streamUrl);
    
    const collectedData: CollectedStreamData = {
      metadata: null,
      propertyInfo: null,
      stats: null,
      rooms: {},
      tasks: {}
    };
    
    let eventCount = 0;
    
    // Timeout de s√©curit√©
    const timeout = setTimeout(() => {
      eventSource.close();
      reject(new Error(`Timeout: extraction trop longue (>${SCRAPING_CONFIG.streaming.extractionTimeout}ms)`));
    }, SCRAPING_CONFIG.streaming.extractionTimeout);
    
    eventSource.onmessage = (event: any) => {
      try {
        const message = JSON.parse(event.data) as SSEEvent;
        eventCount++;
        
        console.log(`   üì® √âv√©nement ${eventCount}: ${message.type}`);
        
        switch (message.type) {
          case 'metadata':
            collectedData.metadata = message.data;
            break;
            
          case 'property_info':
            collectedData.propertyInfo = message.data;
            console.log(`      Propri√©t√©: ${message.data.name}`);
            break;
            
          case 'stats':
            collectedData.stats = message.data;
            console.log(`      Stats: ${message.data.rooms_found} pi√®ces, ${message.data.total_images} images`);
            break;
            
          case 'room':
            collectedData.rooms[message.room_type] = message.data;
            console.log(`      Pi√®ce: ${message.room_type} (${message.data.images_count} images)`);
            break;
            
          case 'tasks':
            collectedData.tasks[message.room_type] = message.data;
            console.log(`      T√¢ches: ${message.room_type} (${message.data.total_tasks} t√¢ches)`);
            break;
            
          case 'complete':
            clearTimeout(timeout);
            eventSource.close();
            console.log(`‚úÖ Stream termin√©: ${eventCount} √©v√©nements re√ßus`);
            resolve(collectedData);
            break;
            
          case 'error':
            clearTimeout(timeout);
            eventSource.close();
            reject(new Error(message.error));
            break;
        }
      } catch (err) {
        console.error('‚ùå Erreur parsing SSE:', err);
      }
    };
    
    eventSource.onerror = (error: any) => {
      clearTimeout(timeout);
      eventSource.close();
      console.error('‚ùå Erreur connexion SSE:', error);
      reject(new Error('Erreur de connexion au stream'));
    };
  });
}

/**
 * D√©termine le type de parcours bas√© sur les donn√©es scrap√©es
 * Par d√©faut: 'menage' (peut √™tre √©tendu avec de la logique plus complexe)
 */
function determineParcoursType(data: CollectedStreamData): 'menage' | 'voyageur' {
  // Pour l'instant, on retourne toujours 'menage'
  // Cette fonction peut √™tre √©tendue pour analyser les donn√©es et d√©terminer le type
  // Par exemple: si beaucoup de t√¢ches li√©es au check-in/check-out ‚Üí 'voyageur'
  
  return 'menage';
}

/**
 * Extrait l'emoji d'un titre de t√¢che
 */
function extractEmoji(title: string): string {
  const emojiMatch = title.match(/^([\u{1F300}-\u{1F9FF}])/u);
  return emojiMatch ? emojiMatch[1] : '‚úì';
}

/**
 * Nettoie le titre en retirant l'emoji
 */
function cleanTitle(title: string): string {
  return title.replace(/^[\u{1F300}-\u{1F9FF}\s]+/u, '').trim();
}

/**
 * Transforme les donn√©es scrap√©es en format parcours CheckEasy
 * T√©l√©charge et convertit les images en base64
 */
async function transformToParcoursFormat(
  data: CollectedStreamData,
  parcoursType: 'menage' | 'voyageur'
): Promise<Omit<ScrapingResult, 'extractionId' | 'parcoursType'>> {

  console.log(`üîÑ Transformation des donn√©es en format parcours...`);

  const pieces = await Promise.all(
    Object.entries(data.rooms).map(async ([roomType, roomData]) => {
      const tasksData = data.tasks[roomType];

      // Mapper le nom de la pi√®ce
      const mappedRoomName = SCRAPING_CONFIG.roomTypeMapping[roomType as keyof typeof SCRAPING_CONFIG.roomTypeMapping] || roomType;

      // Transformer les t√¢ches AI
      const tasks = tasksData?.ai_generated_tasks.map((task: AIGeneratedTask) => ({
        emoji: extractEmoji(task.title),
        titre: cleanTitle(task.title),
        description: task.description,
        photoObligatoire: task.photo_required
      })) || [];

      console.log(`\n   üè† ${mappedRoomName}: ${tasks.length} t√¢ches, ${roomData.images.length} photos`);

      // T√©l√©charger et convertir les photos en base64
      const photosBase64 = await downloadRoomImages(roomData.images);

      return {
        nom: mappedRoomName,
        quantite: 1,
        tasks,
        photos: photosBase64 // Maintenant ce sont des strings base64
      };
    })
  );

  const totalTasks = pieces.reduce((sum, piece) => sum + piece.tasks.length, 0);
  const totalImages = pieces.reduce((sum, piece) => sum + piece.photos.length, 0);

  console.log(`\n‚úÖ Transformation termin√©e: ${pieces.length} pi√®ces, ${totalTasks} t√¢ches, ${totalImages} images`);

  return {
    propertyInfo: {
      name: data.propertyInfo?.name || 'Propri√©t√© Airbnb',
      title: data.propertyInfo?.title || 'Propri√©t√© Airbnb',
      totalImages: data.stats?.total_images || 0
    },
    pieces,
    stats: {
      totalRooms: pieces.length,
      totalTasks,
      totalImages
    }
  };
}

/**
 * Fonction principale : Scrape et cr√©e le parcours
 */
export async function scrapeAndCreateParcours(
  payload: ScrapeAndCreateParcoursPayload
): Promise<ScrapingResult> {
  
  const { url, conciergerieID, userID, isTestMode, parcoursType: requestedParcoursType } = payload;
  
  console.log(`\n${'='.repeat(60)}`);
  console.log(`üöÄ SCRAPING ET CR√âATION DE PARCOURS`);
  console.log(`${'='.repeat(60)}`);
  console.log(`   URL Airbnb: ${url}`);
  console.log(`   Conciergerie: ${conciergerieID}`);
  console.log(`   User: ${userID}`);
  console.log(`   Mode test: ${isTestMode ? 'OUI' : 'NON'}`);
  console.log(`${'='.repeat(60)}\n`);
  
  try {
    // 1. Lancer l'extraction
    const extractionId = await startExtraction(url);
    
    // 2. √âcouter le stream et collecter les donn√©es
    const scrapedData = await listenToStream(extractionId);
    
    // 3. D√©terminer le type de parcours (√âTAPE 2 OBLIGATOIRE)
    const parcoursType = requestedParcoursType || determineParcoursType(scrapedData);
    console.log(`\nüìã Type de parcours d√©termin√©: ${parcoursType.toUpperCase()}`);

    // 4. Transformer en format parcours et t√©l√©charger les images en base64
    console.log(`\nüì• T√©l√©chargement et conversion des images en base64...`);
    const parcoursData = await transformToParcoursFormat(scrapedData, parcoursType);
    
    // 5. Pr√©parer les donn√©es pour le webhook
    const logementData = {
      nom: parcoursData.propertyInfo.name,
      logementId: extractionId,
      modele: parcoursType,
      pieces: parcoursData.pieces,
      piecesPhotos: parcoursData.pieces.reduce((acc, piece) => {
        acc[piece.nom] = piece.photos;
        return acc;
      }, {} as Record<string, any[]>)
    };
    
    // 6. Envoyer webhook √† Bubble.io
    console.log(`\nüì§ Envoi du webhook √† Bubble.io...`);
    await sendWebhookToBubble({
      conciergerieID,
      userID,
      isTestMode,
      logementData
    });
    
    console.log(`\n${'='.repeat(60)}`);
    console.log(`‚úÖ PARCOURS CR√â√â AVEC SUCC√àS`);
    console.log(`${'='.repeat(60)}\n`);
    
    return {
      extractionId,
      parcoursType,
      ...parcoursData
    };
    
  } catch (error) {
    console.error(`\n${'='.repeat(60)}`);
    console.error(`‚ùå ERREUR LORS DU SCRAPING`);
    console.error(`${'='.repeat(60)}`);
    console.error(error);
    console.error(`${'='.repeat(60)}\n`);
    throw error;
  }
}

